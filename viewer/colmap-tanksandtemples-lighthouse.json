{
  "state": {
    "render_resolution": 512,
    "prerender_enabled": false,
    "method_info": {
      "method_id": "colmap",
      "hparams": {
        "mesher": "poisson",
        "PatchMatchStereo.geom_consistency": "true"
      },
      "supported_camera_models": [
        "full_opencv",
        "opencv",
        "opencv_fisheye",
        "pinhole"
      ],
      "supported_outputs": [
        "color",
        "depth"
      ],
      "name": "COLMAP",
      "description": "COLMAP Multi-View Stereo (MVS) is a general-purpose, end-to-end image-based 3D reconstruction pipeline.\nIt uses the point cloud if available, otherwise it runs a sparse reconstruction to obtained.\nThe reconstruction consists of a stereo matching step, followed by a multi-view stereo step to obtain a dense point cloud.\nFinally, either Delaunay or Poisson meshing is used to obtain a mesh from the point cloud.\n",
      "paper_title": "Pixelwise View Selection for Unstructured Multi-View Stereo",
      "paper_authors": [
        "Johannes Lutz Sch\u0151nberger",
        "Enliang Zheng",
        "Marc Pollefeys",
        "Jan-Michael Frahm"
      ],
      "paper_link": "https://demuc.de/papers/schoenberger2016mvs.pdf",
      "link": "https://colmap.github.io/",
      "licenses": [
        {
          "name": "BSD",
          "url": "https://colmap.github.io/license.html"
        }
      ],
      "nb_version": "1.0.3.dev2+g00cf083.d20240819",
      "num_iterations": 1,
      "total_train_time": 9967.82063,
      "resources_utilization": {
        "memory": 669,
        "gpu_name": "",
        "gpu_memory": 0
      },
      "datetime": "2024-09-01T21:08:23",
      "config_overrides": {},
      "applied_presets": [],
      "evaluation_protocol": "default",
      "checkpoint_sha256": "0d465a30fceee148ae78e430eba8b756491b717dec51ddad20b68bf779640c37"
    },
    "dataset_info": {
      "id": "tanksandtemples",
      "color_space": "srgb",
      "evaluation_protocol": "default",
      "scene": "lighthouse",
      "type": "object-centric",
      "downscale_factor": 2,
      "expected_scene_scale": 5.247642803192138,
      "name": "Tanks and Temples",
      "description": "Tanks and Temples is a benchmark for image-based 3D reconstruction. The benchmark sequences were acquired outside the lab, in realistic conditions. Ground-truth data was captured using an industrial laser scanner. The benchmark includes both outdoor scenes and indoor environments. The dataset is split into three subsets: training, intermediate, and advanced.",
      "paper_title": "Tanks and Temples: Benchmarking Large-Scale Scene Reconstruction",
      "paper_authors": [
        "Arno Knapitsch",
        "Jaesik Park",
        "Qian-Yi Zhou",
        "Vladlen Koltun"
      ],
      "paper_link": "https://storage.googleapis.com/t2-downloads/paper/tanks-and-temples.pdf",
      "link": "https://www.tanksandtemples.org/",
      "metrics": [
        {
          "id": "psnr",
          "name": "PSNR",
          "description": "Peak Signal to Noise Ratio. The higher the better.",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio"
        },
        {
          "id": "ssim",
          "name": "SSIM",
          "description": "Structural Similarity Index. The higher the better. The implementation matches JAX's SSIM and torchmetrics's SSIM (with default parameters).",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Structural_similarity"
        },
        {
          "id": "lpips",
          "name": "LPIPS",
          "description": "Learned Perceptual Image Patch Similarity. The lower the better. The implementation uses AlexNet backbone and matches lpips pip package with checkpoint version 0.1",
          "ascending": false,
          "link": "https://richzhang.github.io/PerceptualSimilarity/"
        }
      ],
      "default_metric": "psnr",
      "scenes": [
        {
          "id": "auditorium",
          "name": "auditorium"
        },
        {
          "id": "ballroom",
          "name": "ballroom"
        },
        {
          "id": "courtroom",
          "name": "courtroom"
        },
        {
          "id": "museum",
          "name": "museum"
        },
        {
          "id": "palace",
          "name": "palace"
        },
        {
          "id": "temple",
          "name": "temple"
        },
        {
          "id": "family",
          "name": "family"
        },
        {
          "id": "francis",
          "name": "francis"
        },
        {
          "id": "horse",
          "name": "horse"
        },
        {
          "id": "lighthouse",
          "name": "lighthouse"
        },
        {
          "id": "m60",
          "name": "m60"
        },
        {
          "id": "panther",
          "name": "panther"
        },
        {
          "id": "playground",
          "name": "playground"
        },
        {
          "id": "train",
          "name": "train"
        },
        {
          "id": "barn",
          "name": "barn"
        },
        {
          "id": "caterpillar",
          "name": "caterpillar"
        },
        {
          "id": "church",
          "name": "church"
        },
        {
          "id": "courthouse",
          "name": "courthouse"
        },
        {
          "id": "ignatius",
          "name": "ignatius"
        },
        {
          "id": "meetingroom",
          "name": "meetingroom"
        },
        {
          "id": "truck",
          "name": "truck"
        }
      ]
    }
  },
  "method_id": "colmap",
  "renderer": {
    "mesh_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/colmap/tanksandtemples/lighthouse_demo/mesh.ply",
    "type": "mesh",
    "scene_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/colmap/tanksandtemples/lighthouse_demo/params.json"
  },
  "dataset": {
    "url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-data/resolve/main/tanksandtemples/lighthouse-nbv.json"
  },
  "viewer_transform": [
    0.1601845667944689,
    -0.010898171872375234,
    -0.0734280992555053,
    0.07989634880156386,
    0.07414356760807472,
    0.014945776361461936,
    0.15952713356418835,
    -0.05043774790801378,
    -0.003631366910741246,
    -0.17557735434456526,
    0.018137242438363264,
    -0.11840267973814728
  ],
  "viewer_initial_pose": [
    0.7398270358390047,
    -0.05055881430177921,
    -0.6708947525227973,
    0.6052086599262378,
    0.672702008928279,
    0.03882472731310614,
    0.7388941758932333,
    -0.6651011707736184,
    -0.011310311892569555,
    -0.9979661984037033,
    0.06273459701908762,
    -0.13059971282036426
  ]
}