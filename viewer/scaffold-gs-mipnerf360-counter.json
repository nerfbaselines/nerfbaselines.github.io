{
  "state": {
    "dataset_info": {
      "id": "mipnerf360",
      "color_space": "srgb",
      "evaluation_protocol": "nerf",
      "scene": "counter",
      "downscale_factor": 2,
      "type": "object-centric",
      "expected_scene_scale": 4.36344952583313,
      "name": "Mip-NeRF 360",
      "description": "Mip-NeRF 360 is a collection of four indoor and five outdoor object-centric scenes. The camera trajectory is an orbit around the object with fixed elevation and radius. The test set takes each n-th frame of the trajectory as test views.",
      "paper_title": "Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields",
      "paper_authors": [
        "Jonathan T. Barron",
        "Ben Mildenhall",
        "Dor Verbin",
        "Pratul P. Srinivasan",
        "Peter Hedman"
      ],
      "paper_link": "https://arxiv.org/pdf/2111.12077.pdf",
      "link": "https://jonbarron.info/mipnerf360/",
      "metrics": [
        {
          "id": "psnr",
          "name": "PSNR",
          "description": "Peak Signal to Noise Ratio. The higher the better.",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio"
        },
        {
          "id": "ssim",
          "name": "SSIM",
          "description": "Structural Similarity Index. The higher the better. The implementation matches JAX's SSIM and torchmetrics's SSIM (with default parameters).",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Structural_similarity"
        },
        {
          "id": "lpips_vgg",
          "name": "LPIPS (VGG)",
          "description": "Learned Perceptual Image Patch Similarity. The lower the better. The implementation uses VGG backbone and matches lpips pip package with checkpoint version 0.1",
          "ascending": false,
          "link": "https://richzhang.github.io/PerceptualSimilarity/"
        }
      ],
      "default_metric": "psnr",
      "scenes": [
        {
          "id": "garden",
          "name": "garden"
        },
        {
          "id": "bicycle",
          "name": "bicycle"
        },
        {
          "id": "flowers",
          "name": "flowers"
        },
        {
          "id": "treehill",
          "name": "treehill"
        },
        {
          "id": "stump",
          "name": "stump"
        },
        {
          "id": "kitchen",
          "name": "kitchen"
        },
        {
          "id": "bonsai",
          "name": "bonsai"
        },
        {
          "id": "counter",
          "name": "counter"
        },
        {
          "id": "room",
          "name": "room"
        }
      ]
    },
    "render_resolution": 768,
    "prerender_enabled": false,
    "method_info": {
      "method_id": "scaffold-gs",
      "hparams": {
        "sh_degree": 3,
        "feat_dim": 32,
        "n_offsets": 10,
        "voxel_size": 0.001,
        "update_depth": 3,
        "update_init_factor": 16,
        "update_hierachy_factor": 4,
        "use_feat_bank": false,
        "white_background": false,
        "lod": 0,
        "appearance_dim": 0,
        "lowpoly": false,
        "ds": 1,
        "ratio": 1,
        "undistorted": false,
        "add_opacity_dist": false,
        "add_cov_dist": false,
        "add_color_dist": false,
        "scale_coords": null,
        "iterations": 30000,
        "position_lr_init": 0.0,
        "position_lr_final": 0.0,
        "position_lr_delay_mult": 0.01,
        "position_lr_max_steps": 30000,
        "offset_lr_init": 0.01,
        "offset_lr_final": 0.0001,
        "offset_lr_delay_mult": 0.01,
        "offset_lr_max_steps": 30000,
        "feature_lr": 0.0075,
        "opacity_lr": 0.02,
        "scaling_lr": 0.007,
        "rotation_lr": 0.002,
        "mlp_opacity_lr_init": 0.002,
        "mlp_opacity_lr_final": 2e-05,
        "mlp_opacity_lr_delay_mult": 0.01,
        "mlp_opacity_lr_max_steps": 30000,
        "mlp_cov_lr_init": 0.004,
        "mlp_cov_lr_final": 0.004,
        "mlp_cov_lr_delay_mult": 0.01,
        "mlp_cov_lr_max_steps": 30000,
        "mlp_color_lr_init": 0.008,
        "mlp_color_lr_final": 5e-05,
        "mlp_color_lr_delay_mult": 0.01,
        "mlp_color_lr_max_steps": 30000,
        "mlp_featurebank_lr_init": 0.01,
        "mlp_featurebank_lr_final": 1e-05,
        "mlp_featurebank_lr_delay_mult": 0.01,
        "mlp_featurebank_lr_max_steps": 30000,
        "appearance_lr_init": 0.05,
        "appearance_lr_final": 0.0005,
        "appearance_lr_delay_mult": 0.01,
        "appearance_lr_max_steps": 30000,
        "percent_dense": 0.01,
        "lambda_dssim": 0.2,
        "start_stat": 500,
        "update_from": 1500,
        "update_interval": 100,
        "update_until": 15000,
        "min_opacity": 0.005,
        "success_threshold": 0.8,
        "densify_grad_threshold": 0.0002,
        "test_optim_lr": 0.1,
        "test_optim_steps": 128,
        "convert_SHs_python": false,
        "compute_cov3D_python": false,
        "debug": false
      },
      "supported_camera_models": [
        "pinhole"
      ],
      "supported_outputs": [
        "color"
      ],
      "name": "Scaffold-GS",
      "description": "Scaffold-GS uses anchor points to distribute local 3D Gaussians, and predicts their attributes on-the-fly based on viewing direction and distance within the view frustum. In NerfBaselines, we fixed bug with cx,cy, added appearance embedding optimization, and added support for masks. Note, that we also implement a demo for the method, but it does not evaluate the MLP and the Gaussians are \"baked\" for specific viewing direction and appearance embedding (if enabled).",
      "paper_title": "Scaffold-GS: Structured 3D Gaussians for View-Adaptive Rendering",
      "paper_authors": [
        "Tao Lu",
        "Mulin Yu",
        "Linning Xu",
        "Yuanbo Xiangli",
        "Limin Wang",
        "Dahua LinBo Dai"
      ],
      "paper_link": "https://arxiv.org/pdf/2312.00109.pdf",
      "link": "https://city-super.github.io/scaffold-gs/",
      "licenses": [
        {
          "name": "custom, research only",
          "url": "https://raw.githubusercontent.com/city-super/Scaffold-GS/main/LICENSE.md"
        }
      ],
      "nb_version": "1.1.1.dev6+g5df36ec.d20240910",
      "num_iterations": 30000,
      "total_train_time": 1713.14573,
      "resources_utilization": {
        "memory": 4073,
        "gpu_name": "NVIDIA A100-SXM4-40GB",
        "gpu_memory": 10626
      },
      "datetime": "2024-09-12T18:35:04",
      "config_overrides": {
        "voxel_size": 0.001,
        "update_init_factor": 16,
        "appearance_dim": 0,
        "ratio": 1
      },
      "applied_presets": [
        "mipnerf360"
      ],
      "dataset_metadata": {
        "id": "mipnerf360",
        "color_space": "srgb",
        "evaluation_protocol": "nerf",
        "scene": "counter",
        "downscale_factor": 2,
        "type": "object-centric",
        "viewer_transform": [
          [
            0.15578,
            0.105572,
            -0.136506,
            0.079134
          ],
          [
            0.172219,
            -0.083445,
            0.132,
            -0.146885
          ],
          [
            0.010946,
            -0.189573,
            -0.134122,
            0.544036
          ]
        ],
        "viewer_initial_pose": [
          [
            -0.270569,
            0.540047,
            -0.796958,
            0.776702
          ],
          [
            0.962571,
            0.16536,
            -0.214742,
            0.131314
          ],
          [
            0.015814,
            -0.825231,
            -0.564574,
            0.400459
          ]
        ],
        "expected_scene_scale": 4.36345
      },
      "evaluation_protocol": "nerf",
      "checkpoint_sha256": "a73135992fc2726854b37ac89c056324223fcd07152cc891bd2aa90cc63f854a"
    },
    "outputs_configuration": {
      "color": {}
    }
  },
  "viewer_transform": [
    0.15577992373765237,
    0.10557218681215286,
    -0.13650593106921163,
    0.0791340648993877,
    0.17221945396010707,
    -0.08344548914049088,
    0.13200019264286664,
    -0.14688512926281708,
    0.010946106802707134,
    -0.18957348156751969,
    -0.13412239858718253,
    0.5440358197498617
  ],
  "viewer_initial_pose": [
    -0.27056928407005215,
    0.5400467568517372,
    -0.7969578414552986,
    0.7767020994979709,
    0.9625706093267021,
    0.1653598127117572,
    -0.2147416307338941,
    0.13131370970970474,
    0.015814311950124723,
    -0.8252306408910235,
    -0.5645744196555283,
    0.40045901239675374
  ],
  "method_id": "scaffold-gs",
  "renderer": {
    "scene_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/scaffold-gs/mipnerf360/counter_demo/scene.ksplat",
    "type": "3dgs"
  },
  "dataset": {
    "url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-data/resolve/main/mipnerf360/counter-nbv.json"
  }
}