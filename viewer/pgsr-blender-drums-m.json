{
  "state": {
    "outputs_configuration": {
      "depth": {
        "range_min": 2,
        "range_max": 6,
        "palette_enabled": true
      },
      "color": {},
      "normal": {},
      "accumulation": {
        "palette_enabled": true,
        "range_min": 0,
        "range_max": 1
      }
    },
    "dataset_info": {
      "color_space": "srgb",
      "expected_scene_scale": 4,
      "depth_range": [
        2,
        6
      ],
      "background_color": [
        255,
        255,
        255
      ],
      "id": "blender",
      "scene": "drums",
      "evaluation_protocol": "nerf",
      "type": "object-centric",
      "name": "Blender",
      "description": "Blender (nerf-synthetic) is a synthetic dataset used to benchmark NeRF methods. It consists of 8 scenes of an object placed on a white background. Cameras are placed on a semi-sphere around the object. Scenes are licensed under various CC licenses.",
      "paper_title": "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis",
      "paper_authors": [
        "Ben Mildenhall",
        "Pratul P. Srinivasan",
        "Matthew Tancik",
        "Jonathan T. Barron",
        "Ravi Ramamoorthi",
        "Ren Ng"
      ],
      "paper_link": "https://arxiv.org/pdf/2003.08934.pdf",
      "link": "https://www.matthewtancik.com/nerf",
      "metrics": [
        {
          "id": "psnr",
          "name": "PSNR",
          "description": "Peak Signal to Noise Ratio. The higher the better.",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio"
        },
        {
          "id": "ssim",
          "name": "SSIM",
          "description": "Structural Similarity Index. The higher the better. The implementation matches JAX's SSIM and torchmetrics's SSIM (with default parameters).",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Structural_similarity"
        },
        {
          "id": "lpips_vgg",
          "name": "LPIPS (VGG)",
          "description": "Learned Perceptual Image Patch Similarity. The lower the better. The implementation uses VGG backbone and matches lpips pip package with checkpoint version 0.1",
          "ascending": false,
          "link": "https://richzhang.github.io/PerceptualSimilarity/"
        }
      ],
      "default_metric": "psnr",
      "scenes": [
        {
          "id": "lego",
          "name": "lego"
        },
        {
          "id": "drums",
          "name": "drums"
        },
        {
          "id": "ficus",
          "name": "ficus"
        },
        {
          "id": "hotdog",
          "name": "hotdog"
        },
        {
          "id": "materials",
          "name": "materials"
        },
        {
          "id": "mic",
          "name": "mic"
        },
        {
          "id": "ship",
          "name": "ship"
        },
        {
          "id": "chair",
          "name": "chair"
        }
      ]
    },
    "render_resolution": 768,
    "prerender_enabled": false,
    "method_info": {
      "method_id": "pgsr",
      "hparams": {
        "sh_degree": 3,
        "white_background": true,
        "preload_img": true,
        "ncc_scale": 1.0,
        "multi_view_num": 8,
        "multi_view_max_angle": 30,
        "multi_view_min_dis": 0.01,
        "multi_view_max_dis": 1.5,
        "iterations": 30000,
        "position_lr_init": 0.00016,
        "position_lr_final": 1.6e-06,
        "position_lr_delay_mult": 0.01,
        "position_lr_max_steps": 30000,
        "feature_lr": 0.0025,
        "opacity_lr": 0.05,
        "scaling_lr": 0.005,
        "rotation_lr": 0.001,
        "percent_dense": 0.001,
        "lambda_dssim": 0.2,
        "densification_interval": 100,
        "opacity_reset_interval": 3000,
        "densify_from_iter": 500,
        "densify_until_iter": 15000,
        "densify_grad_threshold": 0.0002,
        "scale_loss_weight": 100.0,
        "wo_image_weight": false,
        "single_view_weight": 0.015,
        "single_view_weight_from_iter": 7000,
        "use_virtul_cam": false,
        "virtul_cam_prob": 0.5,
        "use_multi_view_trim": true,
        "multi_view_ncc_weight": 0.15,
        "multi_view_geo_weight": 0.03,
        "multi_view_weight_from_iter": 7000,
        "multi_view_patch_size": 3,
        "multi_view_sample_num": 102400,
        "multi_view_pixel_noise_th": 1.0,
        "wo_use_geo_occ_aware": false,
        "opacity_cull_threshold": 0.005,
        "densify_abs_grad_threshold": 0.0008,
        "abs_split_radii2D_threshold": 20,
        "max_abs_split_points": 50000,
        "max_all_points": 6000000,
        "exposure_compensation": false,
        "random_background": false,
        "compute_cov3D_python": false,
        "max_depth": 5.0,
        "voxel_size": 0.002,
        "num_images": 1600,
        "num_cluster": 1,
        "use_depth_filter": true
      },
      "supported_camera_models": [
        "pinhole"
      ],
      "supported_outputs": [
        "accumulation",
        "color",
        "depth",
        "normal"
      ],
      "name": "PGSR",
      "description": "Planar-based Gaussian Splatting Reconstruction representation for efficient and high-fidelity surface reconstruction from multi-view RGB images without any geometric prior (depth or normal from pre-trained model).",
      "paper_title": "PGSR: Planar-based Gaussian Splatting for Efficient and High-Fidelity Surface Reconstruction",
      "paper_authors": [
        "Danpeng Chen",
        "Hai Li",
        "Weicai Ye",
        "Yifan Wang",
        "Weijian Xie",
        "Shangjin Zhai",
        "Nan Wang",
        "Haomin Liu",
        "Hujun Bao",
        "Guofeng Zhang"
      ],
      "paper_link": "https://zju3dv.github.io/pgsr/paper/pgsr.pdf",
      "link": "https://zju3dv.github.io/pgsr/",
      "licenses": [
        {
          "name": "custom, research only",
          "url": "https://raw.githubusercontent.com/zju3dv/PGSR/refs/heads/main/LICENSE.md"
        }
      ],
      "nb_version": "1.2.9.dev0+g09eaa2c.d20250222",
      "num_iterations": 30000,
      "total_train_time": 498.65903,
      "resources_utilization": {
        "memory": 3987,
        "gpu_name": "NVIDIA A100-SXM4-40GB",
        "gpu_memory": 4104
      },
      "datetime": "2025-03-28T08:34:29",
      "config_overrides": {
        "white_background": true,
        "num_cluster": 1,
        "use_depth_filter": true
      },
      "applied_presets": [
        "blender"
      ],
      "dataset_metadata": {
        "color_space": "srgb",
        "expected_scene_scale": 4,
        "depth_range": [
          2,
          6
        ],
        "background_color": [
          255,
          255,
          255
        ],
        "id": "blender",
        "scene": "drums",
        "evaluation_protocol": "nerf",
        "type": "object-centric",
        "viewer_transform": [
          0.233781,
          0.041763,
          -0.005102,
          0.0,
          -0.041899,
          0.233714,
          -0.006771,
          0.0,
          0.003829,
          0.007564,
          0.237385,
          0.0
        ],
        "viewer_initial_pose": [
          0.046754,
          -0.851644,
          0.522031,
          -0.499865,
          -0.998529,
          -0.025471,
          0.047876,
          -0.045843,
          -0.027476,
          -0.523501,
          -0.851582,
          0.815423
        ]
      },
      "evaluation_protocol": "nerf",
      "checkpoint_sha256": "f530601f8c5d74152bed9ad638232d97deeef3ca2759688dbd76da05b4227b86"
    }
  },
  "viewer_transform": [
    0.23378053111752,
    0.04176272097533595,
    -0.005101554485803457,
    1.212545071294091e-09,
    -0.04189856245458773,
    0.2337138173700361,
    -0.006770974607286131,
    2.0343422085788987e-09,
    0.0038290131136860485,
    0.007563770228847798,
    0.23738494237270985,
    2.567753787374727e-10
  ],
  "viewer_initial_pose": [
    0.04675402447987858,
    -0.8516441730000772,
    0.5220309648324886,
    -0.4998651409608372,
    -0.9985285667177936,
    -0.025471302242835323,
    0.047875928602504725,
    -0.045843079064837255,
    -0.027476441547764876,
    -0.5235011008876568,
    -0.8515819427686113,
    0.8154231121581405
  ],
  "method_id": "pgsr",
  "renderer": {
    "type": "mesh",
    "mesh_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/pgsr/blender/drums_mesh/mesh.ply"
  },
  "dataset": {
    "url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-data/resolve/main/blender/drums-nbv.json"
  }
}