{
  "state": {
    "dataset_info": {
      "id": "mipnerf360-sparse",
      "color_space": "srgb",
      "evaluation_protocol": "nerf",
      "scene": "bonsai-n12",
      "downscale_factor": 2,
      "type": "object-centric",
      "expected_scene_scale": 4.055882930755615,
      "name": "Mip-NeRF 360 Sparse",
      "description": "Modified Mip-NeRF 360 dataset with small train set (12 or 24) views. The dataset is used to evaluate sparse-view NVS methods.",
      "paper_title": "Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields",
      "paper_authors": [
        "Jonathan T. Barron",
        "Ben Mildenhall",
        "Dor Verbin",
        "Pratul P. Srinivasan",
        "Peter Hedman"
      ],
      "paper_link": "https://arxiv.org/pdf/2111.12077.pdf",
      "link": "https://jonbarron.info/mipnerf360/",
      "metrics": [
        {
          "id": "psnr",
          "name": "PSNR",
          "description": "Peak Signal to Noise Ratio. The higher the better.",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio"
        },
        {
          "id": "ssim",
          "name": "SSIM",
          "description": "Structural Similarity Index. The higher the better. The implementation matches JAX's SSIM and torchmetrics's SSIM (with default parameters).",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Structural_similarity"
        },
        {
          "id": "lpips_vgg",
          "name": "LPIPS (VGG)",
          "description": "Learned Perceptual Image Patch Similarity. The lower the better. The implementation uses VGG backbone and matches lpips pip package with checkpoint version 0.1",
          "ascending": false,
          "link": "https://richzhang.github.io/PerceptualSimilarity/"
        }
      ],
      "default_metric": "psnr",
      "scenes": [
        {
          "id": "garden-n12",
          "name": "garden n12"
        },
        {
          "id": "bicycle-n12",
          "name": "bicycle n12"
        },
        {
          "id": "flowers-n12",
          "name": "flowers n12"
        },
        {
          "id": "treehill-n12",
          "name": "treehill n12"
        },
        {
          "id": "stump-n12",
          "name": "stump n12"
        },
        {
          "id": "kitchen-n12",
          "name": "kitchen n12"
        },
        {
          "id": "bonsai-n12",
          "name": "bonsai n12"
        },
        {
          "id": "counter-n12",
          "name": "counter n12"
        },
        {
          "id": "room-n12",
          "name": "room n12"
        },
        {
          "id": "garden-n24",
          "name": "garden n24"
        },
        {
          "id": "bicycle-n24",
          "name": "bicycle n24"
        },
        {
          "id": "flowers-n24",
          "name": "flowers n24"
        },
        {
          "id": "treehill-n24",
          "name": "treehill n24"
        },
        {
          "id": "stump-n24",
          "name": "stump n24"
        },
        {
          "id": "kitchen-n24",
          "name": "kitchen n24"
        },
        {
          "id": "bonsai-n24",
          "name": "bonsai n24"
        },
        {
          "id": "counter-n24",
          "name": "counter n24"
        },
        {
          "id": "room-n24",
          "name": "room n24"
        }
      ]
    },
    "render_resolution": 768,
    "prerender_enabled": false,
    "method_info": {
      "method_id": "sparsegs",
      "hparams": {
        "sh_degree": 3,
        "white_background": false,
        "no_load_depth": false,
        "lambda_local_pearson": 0.15,
        "lambda_pearson": 0.05,
        "box_p": 128,
        "p_corr": 0.5,
        "prune_exp": 7.5,
        "prune_perc": 0.98,
        "densify_lag": 1000000,
        "power_thresh": -4.0,
        "densify_period": 5000,
        "step_ratio": 0.99,
        "lambda_diffusion": 0.001,
        "SDS_freq": 0.1,
        "lambda_reg": 0.1,
        "warp_reg_start_itr": 4999,
        "init_type": "sfm",
        "scale_coords": null,
        "iterations": 30000,
        "position_lr_init": 0.00016,
        "position_lr_final": 1.6e-06,
        "position_lr_delay_mult": 0.01,
        "position_lr_max_steps": 30000,
        "feature_lr": 0.0025,
        "opacity_lr": 0.05,
        "scaling_lr": 0.005,
        "rotation_lr": 0.001,
        "percent_dense": 0.01,
        "lambda_dssim": 0.2,
        "densification_interval": 100,
        "opacity_reset_interval": 3000,
        "densify_from_iter": 500,
        "densify_until_iter": 18000,
        "densify_grad_threshold": 0.0002,
        "random_background": false,
        "convert_SHs_python": false,
        "compute_cov3D_python": false,
        "debug": false,
        "beta": 5.0
      },
      "supported_camera_models": [
        "pinhole"
      ],
      "supported_outputs": [
        "accumulation",
        "color",
        "depth",
        "normal"
      ],
      "name": "SparseGS",
      "description": "SparseGS augments 3D Gaussian Splatting with depth-based priors, tailored depth rendering, a floater-pruning heuristic, and Unseen Viewpoint Regularization, letting it overcome \u201cfloaters\u201d and background collapse when training views are scarce. Tested on Mip-NeRF360, LLFF, and DTU, it still trains quickly and renders in real time while reconstructing unbounded or forward-facing scenes from as few as 12 and 3 input images, respectively.",
      "paper_title": "SparseGS: Real-Time 360\u00b0 Sparse View Synthesis using Gaussian Splatting",
      "paper_authors": [
        "Haolin Xiong",
        "Sairisheek Muttukuru",
        "Rishi Upadhyay",
        "Pradyumna Chari",
        "Achuta Kadambi"
      ],
      "paper_venue": "3DV 2025",
      "paper_link": "https://arxiv.org/pdf/2312.00206.pdf",
      "link": "https://formycat.github.io/SparseGS-Real-Time-360-Sparse-View-Synthesis-using-Gaussian-Splatting/",
      "licenses": [
        {
          "name": "custom, research only",
          "url": "https://raw.githubusercontent.com/ForMyCat/SparseGS/refs/heads/master/LICENSE.md"
        }
      ],
      "nb_version": "0.1.dev2+g82c8880.d20250730",
      "num_iterations": 30000,
      "total_train_time": 2577.17912,
      "resources_utilization": {
        "memory": 4126,
        "gpu_name": "NVIDIA A100-SXM4-40GB",
        "gpu_memory": 11694
      },
      "datetime": "2025-07-31T02:27:42",
      "config_overrides": {},
      "applied_presets": [],
      "dataset_metadata": {
        "id": "mipnerf360-sparse",
        "color_space": "srgb",
        "evaluation_protocol": "nerf",
        "scene": "bonsai-n12",
        "downscale_factor": 2,
        "type": "object-centric",
        "viewer_transform": [
          0.174764,
          -0.141535,
          0.116451,
          -0.076469,
          -0.182831,
          -0.123324,
          0.124497,
          0.068602,
          -0.012871,
          -0.169984,
          -0.187284,
          0.578997
        ],
        "viewer_initial_pose": [
          -0.309627,
          -0.343316,
          0.886716,
          -1.035941,
          -0.950712,
          0.095455,
          -0.295015,
          0.463993,
          0.016642,
          -0.934357,
          -0.35595,
          0.381918
        ],
        "expected_scene_scale": 4.055883
      },
      "evaluation_protocol": "nerf",
      "checkpoint_sha256": "b6d8378d17257d4ce017ca44efa3e3896c735925d7d4b9472fdff2d162e8d0e1"
    },
    "outputs_configuration": {
      "color": {},
      "depth": {
        "palette_enabled": true
      },
      "accumulation": {
        "palette_enabled": true,
        "range_min": 0,
        "range_max": 1
      },
      "normal": {}
    }
  },
  "viewer_transform": [
    0.17476449938397168,
    -0.1415349601691969,
    0.11645071322453887,
    -0.0764690359174753,
    -0.1828312454758501,
    -0.12332411893651761,
    0.12449675669636277,
    0.06860168702772679,
    -0.012870533217417815,
    -0.16998399798884548,
    -0.18728409753017863,
    0.5789966217633002
  ],
  "viewer_initial_pose": [
    -0.30962704596548607,
    -0.3433160707023378,
    0.8867159305363789,
    -1.0359407737822157,
    -0.9507124670849924,
    0.09545539724093167,
    -0.29501545810269386,
    0.46399276564943803,
    0.016641727684817746,
    -0.9343566082881075,
    -0.35595042714935,
    0.38191798235694796
  ],
  "method_id": "sparsegs",
  "renderer": {
    "scene_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/sparsegs/mipnerf360-sparse/bonsai-n12_demo/scene.ksplat",
    "type": "3dgs"
  },
  "dataset": {
    "url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-data/resolve/main/mipnerf360-sparse/bonsai-n12-nbv.json"
  }
}