{
  "state": {
    "dataset_info": {
      "id": "mipnerf360-sparse",
      "color_space": "srgb",
      "evaluation_protocol": "nerf",
      "scene": "flowers-n24",
      "downscale_factor": 4,
      "type": "object-centric",
      "expected_scene_scale": 4.099789476394653,
      "name": "Mip-NeRF 360 Sparse",
      "description": "Modified Mip-NeRF 360 dataset with small train set (12 or 24) views. The dataset is used to evaluate sparse-view NVS methods.",
      "paper_title": "Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields",
      "paper_authors": [
        "Jonathan T. Barron",
        "Ben Mildenhall",
        "Dor Verbin",
        "Pratul P. Srinivasan",
        "Peter Hedman"
      ],
      "paper_link": "https://arxiv.org/pdf/2111.12077.pdf",
      "link": "https://jonbarron.info/mipnerf360/",
      "metrics": [
        {
          "id": "psnr",
          "name": "PSNR",
          "description": "Peak Signal to Noise Ratio. The higher the better.",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio"
        },
        {
          "id": "ssim",
          "name": "SSIM",
          "description": "Structural Similarity Index. The higher the better. The implementation matches JAX's SSIM and torchmetrics's SSIM (with default parameters).",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Structural_similarity"
        },
        {
          "id": "lpips_vgg",
          "name": "LPIPS (VGG)",
          "description": "Learned Perceptual Image Patch Similarity. The lower the better. The implementation uses VGG backbone and matches lpips pip package with checkpoint version 0.1",
          "ascending": false,
          "link": "https://richzhang.github.io/PerceptualSimilarity/"
        }
      ],
      "default_metric": "psnr",
      "scenes": [
        {
          "id": "garden-n12",
          "name": "garden n12"
        },
        {
          "id": "bicycle-n12",
          "name": "bicycle n12"
        },
        {
          "id": "flowers-n12",
          "name": "flowers n12"
        },
        {
          "id": "treehill-n12",
          "name": "treehill n12"
        },
        {
          "id": "stump-n12",
          "name": "stump n12"
        },
        {
          "id": "kitchen-n12",
          "name": "kitchen n12"
        },
        {
          "id": "bonsai-n12",
          "name": "bonsai n12"
        },
        {
          "id": "counter-n12",
          "name": "counter n12"
        },
        {
          "id": "room-n12",
          "name": "room n12"
        },
        {
          "id": "garden-n24",
          "name": "garden n24"
        },
        {
          "id": "bicycle-n24",
          "name": "bicycle n24"
        },
        {
          "id": "flowers-n24",
          "name": "flowers n24"
        },
        {
          "id": "treehill-n24",
          "name": "treehill n24"
        },
        {
          "id": "stump-n24",
          "name": "stump n24"
        },
        {
          "id": "kitchen-n24",
          "name": "kitchen n24"
        },
        {
          "id": "bonsai-n24",
          "name": "bonsai n24"
        },
        {
          "id": "counter-n24",
          "name": "counter n24"
        },
        {
          "id": "room-n24",
          "name": "room n24"
        }
      ]
    },
    "render_resolution": 768,
    "prerender_enabled": false,
    "method_info": {
      "method_id": "3dgs-mcmc",
      "hparams": {
        "sh_degree": 3,
        "white_background": false,
        "cap_max": 3700000,
        "init_type": "sfm",
        "scale_coords": null,
        "iterations": 30000,
        "position_lr_init": 0.00016,
        "position_lr_final": 1.6e-06,
        "position_lr_delay_mult": 0.01,
        "position_lr_max_steps": 30000,
        "feature_lr": 0.0025,
        "opacity_lr": 0.05,
        "scaling_lr": 0.005,
        "rotation_lr": 0.001,
        "percent_dense": 0.01,
        "lambda_dssim": 0.2,
        "densification_interval": 100,
        "opacity_reset_interval": 3000,
        "densify_from_iter": 500,
        "densify_until_iter": 25000,
        "densify_grad_threshold": 0.0002,
        "random_background": false,
        "noise_lr": 500000.0,
        "scale_reg": 0.01,
        "opacity_reg": 0.01,
        "convert_SHs_python": false,
        "compute_cov3D_python": false,
        "debug": false
      },
      "supported_camera_models": [
        "pinhole"
      ],
      "supported_outputs": [
        "accumulation",
        "color",
        "depth",
        "normal"
      ],
      "name": "3DGS-MCMC",
      "description": "3DGS-MCMC reinterprets 3D Gaussian Splatting as MCMC sampling, introducing noise-based updates and removing heuristic cloning strategies, leading to improved rendering quality, efficient Gaussian use, and robustness to initialization. In NerfBaselines, we fixed bug with cx,cy, added appearance embedding optimization, and added support for sampling masks and web demos.",
      "paper_title": "3D Gaussian Splatting as Markov Chain Monte Carlo",
      "paper_authors": [
        "Shakiba Kheradmand",
        "Daniel Rebain",
        "Gopal Sharma",
        "Weiwei Sun",
        "Yang-Che Tseng",
        "Hossam Isack",
        "Abhishek Kar",
        "Andrea Tagliasacchi",
        "Kwang Moo Yi"
      ],
      "paper_link": "https://ubc-vision.github.io/3dgs-mcmc/paper.pdf",
      "link": "https://ubc-vision.github.io/3dgs-mcmc/",
      "licenses": [
        {
          "name": "custom, research only",
          "url": "https://raw.githubusercontent.com/ubc-vision/3dgs-mcmc/refs/heads/main/LICENSE.md"
        }
      ],
      "nb_version": "1.2.9.dev0+g09eaa2c.d20250222",
      "num_iterations": 30000,
      "total_train_time": 2101.37565,
      "resources_utilization": {
        "memory": 3551,
        "gpu_name": "NVIDIA A100-SXM4-40GB",
        "gpu_memory": 39226
      },
      "datetime": "2025-07-29T20:33:51",
      "config_overrides": {
        "cap_max": 3700000
      },
      "applied_presets": [
        "mipnerf360/flowers"
      ],
      "dataset_metadata": {
        "id": "mipnerf360-sparse",
        "color_space": "srgb",
        "evaluation_protocol": "nerf",
        "scene": "flowers-n24",
        "downscale_factor": 4,
        "type": "object-centric",
        "viewer_transform": [
          -0.094182,
          0.072441,
          0.215875,
          0.029168,
          -0.227603,
          -0.022949,
          -0.091597,
          0.012738,
          -0.006823,
          -0.234405,
          0.075682,
          0.011586
        ],
        "viewer_initial_pose": [
          0.334674,
          -0.170905,
          -0.926706,
          0.770316,
          0.941509,
          0.101796,
          0.321246,
          -0.276888,
          0.039432,
          -0.980015,
          0.194978,
          -0.134226
        ],
        "expected_scene_scale": 4.099789
      },
      "evaluation_protocol": "nerf",
      "checkpoint_sha256": "6fdd40fd26dc1ec8ce038a27c59b352fa8d0db5d0fbeaaaf9184474b86612076"
    },
    "outputs_configuration": {
      "color": {},
      "depth": {
        "palette_enabled": true
      },
      "accumulation": {
        "palette_enabled": true,
        "range_min": 0,
        "range_max": 1
      },
      "normal": {}
    }
  },
  "viewer_transform": [
    -0.09418152363756523,
    0.07244089221468795,
    0.21587526688392958,
    0.02916775576710249,
    -0.22760329928196424,
    -0.02294907298341416,
    -0.09159722581646462,
    0.012738475489333045,
    -0.006822851727943513,
    -0.23440484367610467,
    0.0756821735815971,
    0.011585778573210647
  ],
  "viewer_initial_pose": [
    0.3346738997787799,
    -0.17090549381691494,
    -0.9267063435390456,
    0.7703159938110667,
    0.9415086068335075,
    0.10179612886145596,
    0.3212461523307514,
    -0.2768882301037988,
    0.039432390935230106,
    -0.9800147291622328,
    0.1949775351465476,
    -0.1342259276581514
  ],
  "method_id": "3dgs-mcmc",
  "renderer": {
    "scene_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/3dgs-mcmc/mipnerf360-sparse/flowers-n24_demo/scene.ksplat",
    "type": "3dgs"
  },
  "dataset": {
    "url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-data/resolve/main/mipnerf360-sparse/flowers-n24-nbv.json"
  }
}