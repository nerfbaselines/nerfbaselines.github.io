{
  "state": {
    "dataset_info": {
      "name": "Mip-NeRF 360",
      "color_space": "srgb",
      "evaluation_protocol": "nerf",
      "scene": "garden",
      "downscale_factor": 4,
      "expected_scene_scale": 4.101067543029785,
      "type": "object-centric",
      "id": "mipnerf360",
      "description": "Mip-NeRF 360 is a collection of four indoor and five outdoor object-centric scenes. The camera trajectory is an orbit around the object with fixed elevation and radius. The test set takes each n-th frame of the trajectory as test views.",
      "paper_title": "Mip-NeRF 360: Unbounded Anti-Aliased Neural Radiance Fields",
      "paper_authors": [
        "Jonathan T. Barron",
        "Ben Mildenhall",
        "Dor Verbin",
        "Pratul P. Srinivasan",
        "Peter Hedman"
      ],
      "paper_link": "https://arxiv.org/pdf/2111.12077.pdf",
      "link": "https://jonbarron.info/mipnerf360/",
      "metrics": [
        {
          "id": "psnr",
          "name": "PSNR",
          "description": "Peak Signal to Noise Ratio. The higher the better.",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio"
        },
        {
          "id": "ssim",
          "name": "SSIM",
          "description": "Structural Similarity Index. The higher the better. The implementation matches JAX's SSIM and torchmetrics's SSIM (with default parameters).",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Structural_similarity"
        },
        {
          "id": "lpips_vgg",
          "name": "LPIPS (VGG)",
          "description": "Learned Perceptual Image Patch Similarity. The lower the better. The implementation uses VGG backbone and matches lpips pip package with checkpoint version 0.1",
          "ascending": false,
          "link": "https://richzhang.github.io/PerceptualSimilarity/"
        }
      ],
      "default_metric": "psnr",
      "scenes": [
        {
          "id": "garden",
          "name": "garden"
        },
        {
          "id": "bicycle",
          "name": "bicycle"
        },
        {
          "id": "flowers",
          "name": "flowers"
        },
        {
          "id": "treehill",
          "name": "treehill"
        },
        {
          "id": "stump",
          "name": "stump"
        },
        {
          "id": "kitchen",
          "name": "kitchen"
        },
        {
          "id": "bonsai",
          "name": "bonsai"
        },
        {
          "id": "counter",
          "name": "counter"
        },
        {
          "id": "room",
          "name": "room"
        }
      ]
    },
    "render_resolution": 768,
    "prerender_enabled": false,
    "method_info": {
      "method_id": "gaussian-opacity-fields",
      "hparams": {
        "sh_degree": 3,
        "white_background": false,
        "kernel_size": 0.0,
        "ray_jitter": false,
        "resample_gt_image": false,
        "load_allres": false,
        "sample_more_highres": false,
        "use_decoupled_appearance": false,
        "scale_coords": null,
        "iterations": 30000,
        "position_lr_init": 0.00016,
        "position_lr_final": 1.6e-06,
        "position_lr_delay_mult": 0.01,
        "position_lr_max_steps": 30000,
        "feature_lr": 0.0025,
        "opacity_lr": 0.05,
        "scaling_lr": 0.005,
        "rotation_lr": 0.001,
        "appearance_embeddings_lr": 0.001,
        "appearance_network_lr": 0.001,
        "percent_dense": 0.01,
        "lambda_dssim": 0.2,
        "lambda_distortion": 100,
        "lambda_depth_normal": 0.05,
        "distortion_from_iter": 15000,
        "depth_normal_from_iter": 15000,
        "densification_interval": 100,
        "opacity_reset_interval": 3000,
        "densify_from_iter": 500,
        "densify_until_iter": 15000,
        "densify_grad_threshold": 0.0002,
        "convert_SHs_python": false,
        "compute_cov3D_python": false,
        "compute_view2gaussian_python": false,
        "debug": false
      },
      "supported_camera_models": [
        "pinhole"
      ],
      "supported_outputs": [
        "accumulation",
        "color",
        "depth",
        "distortion_map",
        "normal"
      ],
      "name": "Gaussian Opacity Fields",
      "description": "Improved Mip-Splatting with better geometry.",
      "paper_title": "Gaussian Opacity Fields: Efficient and Compact Surface Reconstruction in Unbounded Scenes",
      "paper_authors": [
        "Zehao Yu",
        "Torsten Sattler",
        "Andreas Geiger"
      ],
      "paper_link": "https://arxiv.org/pdf/2404.10772.pdf",
      "link": "https://niujinshuchong.github.io/gaussian-opacity-fields/",
      "licenses": [
        {
          "name": "custom, research only",
          "url": "https://raw.githubusercontent.com/autonomousvision/gaussian-opacity-fields/main/LICENSE.md"
        }
      ],
      "num_iterations": 30000,
      "total_train_time": 4411.52887,
      "resources_utilization": {
        "memory": 8690,
        "gpu_memory": 35420,
        "gpu_name": "NVIDIA A100-SXM4-40GB"
      },
      "datetime": "2024-06-07T12:54:03+0200",
      "config_overrides": {},
      "dataset_metadata": {
        "name": "mipnerf360",
        "color_space": "srgb",
        "evaluation_protocol": "nerf",
        "viewer_transform": [
          [
            -0.057403,
            0.10811,
            -0.201541,
            0.081719
          ],
          [
            0.228696,
            0.025217,
            -0.051611,
            -0.076247
          ],
          [
            -0.002109,
            -0.208033,
            -0.110992,
            0.436519
          ],
          [
            0.0,
            0.0,
            0.0,
            1.0
          ]
        ],
        "viewer_initial_pose": [
          [
            -0.245561,
            0.192971,
            -0.94998,
            1.03697
          ],
          [
            0.96917,
            0.02842,
            -0.244748,
            0.240112
          ],
          [
            -0.020231,
            -0.980793,
            -0.194001,
            0.170598
          ]
        ],
        "scene": "garden",
        "downscale_factor": 4,
        "expected_scene_scale": 4.110425,
        "type": "object-centric"
      },
      "evaluation_protocol": "nerf",
      "nb_version": "0.0.16.dev56+g8ee0779.d20240531",
      "checkpoint_sha256": "b0cf9e58e8b02e04b9c2e43e16ab808543f96469eaa360d5d6dd97512ed1b8d1"
    },
    "outputs_configuration": {
      "color": {},
      "normal": {},
      "depth": {
        "palette_enabled": true
      },
      "accumulation": {
        "palette_enabled": true,
        "range_min": 0,
        "range_max": 1
      },
      "distortion_map": {
        "palette_enabled": true
      }
    }
  },
  "viewer_transform": [
    -0.060159127613912934,
    0.10730773903112355,
    -0.20014781043327937,
    0.08166239754256945,
    0.22708637933654383,
    0.026214964273466538,
    -0.05420119662331633,
    -0.07559332122255462,
    -0.0024234234048181465,
    -0.2073428067605815,
    -0.11043686984214754,
    0.4355414626590412
  ],
  "viewer_initial_pose": [
    -0.06205325107625681,
    0.20093197157545312,
    -0.9776378503560623,
    1.048962666217299,
    0.998066652938876,
    0.015936037074919068,
    -0.06007464409148531,
    0.06536615074217787,
    0.003508747861450171,
    -0.9794755553500759,
    -0.20153237614274824,
    0.17245212573259566
  ],
  "method_id": "gaussian-opacity-fields",
  "renderer": {
    "type": "mesh",
    "mesh_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/gaussian-opacity-fields/mipnerf360/garden_mesh/mesh.ply"
  },
  "dataset": {
    "url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-data/resolve/main/mipnerf360/garden-nbv.json"
  }
}