{
  "state": {
    "render_resolution": 512,
    "prerender_enabled": false,
    "method_info": {
      "method_id": "colmap",
      "hparams": {
        "mesher": "poisson",
        "PatchMatchStereo.geom_consistency": "true"
      },
      "supported_camera_models": [
        "full_opencv",
        "opencv",
        "opencv_fisheye",
        "pinhole"
      ],
      "supported_outputs": [
        "color",
        "depth"
      ],
      "name": "COLMAP",
      "description": "COLMAP Multi-View Stereo (MVS) is a general-purpose, end-to-end image-based 3D reconstruction pipeline.\nIt uses the point cloud if available, otherwise it runs a sparse reconstruction to obtained.\nThe reconstruction consists of a stereo matching step, followed by a multi-view stereo step to obtain a dense point cloud.\nFinally, either Delaunay or Poisson meshing is used to obtain a mesh from the point cloud.\n",
      "paper_title": "Pixelwise View Selection for Unstructured Multi-View Stereo",
      "paper_authors": [
        "Johannes Lutz Sch\u0151nberger",
        "Enliang Zheng",
        "Marc Pollefeys",
        "Jan-Michael Frahm"
      ],
      "paper_link": "https://demuc.de/papers/schoenberger2016mvs.pdf",
      "link": "https://colmap.github.io/",
      "licenses": [
        {
          "name": "BSD",
          "url": "https://colmap.github.io/license.html"
        }
      ],
      "nb_version": "1.0.3.dev2+g00cf083.d20240819",
      "num_iterations": 1,
      "total_train_time": 9692.3896,
      "resources_utilization": {
        "memory": 805,
        "gpu_name": "",
        "gpu_memory": 0
      },
      "datetime": "2024-09-01T21:03:44",
      "config_overrides": {},
      "applied_presets": [],
      "evaluation_protocol": "default",
      "checkpoint_sha256": "f0c6e2aa904e69cad9d212a163fdf241c54b397192b76bdb5df6a0afa45183d4"
    },
    "dataset_info": {
      "id": "tanksandtemples",
      "color_space": "srgb",
      "evaluation_protocol": "default",
      "scene": "horse",
      "type": "object-centric",
      "downscale_factor": 2,
      "expected_scene_scale": 5.619719362258911,
      "name": "Tanks and Temples",
      "description": "Tanks and Temples is a benchmark for image-based 3D reconstruction. The benchmark sequences were acquired outside the lab, in realistic conditions. Ground-truth data was captured using an industrial laser scanner. The benchmark includes both outdoor scenes and indoor environments. The dataset is split into three subsets: training, intermediate, and advanced.",
      "paper_title": "Tanks and Temples: Benchmarking Large-Scale Scene Reconstruction",
      "paper_authors": [
        "Arno Knapitsch",
        "Jaesik Park",
        "Qian-Yi Zhou",
        "Vladlen Koltun"
      ],
      "paper_link": "https://storage.googleapis.com/t2-downloads/paper/tanks-and-temples.pdf",
      "link": "https://www.tanksandtemples.org/",
      "metrics": [
        {
          "id": "psnr",
          "name": "PSNR",
          "description": "Peak Signal to Noise Ratio. The higher the better.",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio"
        },
        {
          "id": "ssim",
          "name": "SSIM",
          "description": "Structural Similarity Index. The higher the better. The implementation matches JAX's SSIM and torchmetrics's SSIM (with default parameters).",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Structural_similarity"
        },
        {
          "id": "lpips",
          "name": "LPIPS",
          "description": "Learned Perceptual Image Patch Similarity. The lower the better. The implementation uses AlexNet backbone and matches lpips pip package with checkpoint version 0.1",
          "ascending": false,
          "link": "https://richzhang.github.io/PerceptualSimilarity/"
        }
      ],
      "default_metric": "psnr",
      "scenes": [
        {
          "id": "auditorium",
          "name": "auditorium"
        },
        {
          "id": "ballroom",
          "name": "ballroom"
        },
        {
          "id": "courtroom",
          "name": "courtroom"
        },
        {
          "id": "museum",
          "name": "museum"
        },
        {
          "id": "palace",
          "name": "palace"
        },
        {
          "id": "temple",
          "name": "temple"
        },
        {
          "id": "family",
          "name": "family"
        },
        {
          "id": "francis",
          "name": "francis"
        },
        {
          "id": "horse",
          "name": "horse"
        },
        {
          "id": "lighthouse",
          "name": "lighthouse"
        },
        {
          "id": "m60",
          "name": "m60"
        },
        {
          "id": "panther",
          "name": "panther"
        },
        {
          "id": "playground",
          "name": "playground"
        },
        {
          "id": "train",
          "name": "train"
        },
        {
          "id": "barn",
          "name": "barn"
        },
        {
          "id": "caterpillar",
          "name": "caterpillar"
        },
        {
          "id": "church",
          "name": "church"
        },
        {
          "id": "courthouse",
          "name": "courthouse"
        },
        {
          "id": "ignatius",
          "name": "ignatius"
        },
        {
          "id": "meetingroom",
          "name": "meetingroom"
        },
        {
          "id": "truck",
          "name": "truck"
        }
      ]
    }
  },
  "method_id": "colmap",
  "renderer": {
    "mesh_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/colmap/tanksandtemples/horse_demo/mesh.ply",
    "type": "mesh",
    "scene_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/colmap/tanksandtemples/horse_demo/params.json"
  },
  "dataset": {
    "url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-data/resolve/main/tanksandtemples/horse-nbv.json"
  },
  "viewer_transform": [
    0.15774727537968022,
    -0.0025767114423917285,
    -0.06659002072433508,
    0.007567460704026831,
    0.06604931318520937,
    -0.0166848361403451,
    0.15711198944251892,
    -0.07273764810592032,
    -0.008852054752966467,
    -0.17041141065716106,
    -0.014375824638087207,
    -0.005475623794708354
  ],
  "viewer_initial_pose": [
    0.9997803826454352,
    -0.013674905275505338,
    0.015879120921089333,
    0.05070009132143838,
    -0.012960518936928728,
    0.191944124351299,
    0.9813202489754347,
    -0.43328800683472757,
    -0.016467368159575956,
    -0.981310574092126,
    0.19172473807642607,
    -0.035227745323484584
  ]
}