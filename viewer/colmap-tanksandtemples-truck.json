{
  "state": {
    "render_resolution": 512,
    "prerender_enabled": false,
    "method_info": {
      "method_id": "colmap",
      "hparams": {
        "mesher": "poisson",
        "PatchMatchStereo.geom_consistency": "true"
      },
      "supported_camera_models": [
        "full_opencv",
        "opencv",
        "opencv_fisheye",
        "pinhole"
      ],
      "supported_outputs": [
        "color",
        "depth"
      ],
      "name": "COLMAP",
      "description": "COLMAP Multi-View Stereo (MVS) is a general-purpose, end-to-end image-based 3D reconstruction pipeline.\nIt uses the point cloud if available, otherwise it runs a sparse reconstruction to obtained.\nThe reconstruction consists of a stereo matching step, followed by a multi-view stereo step to obtain a dense point cloud.\nFinally, either Delaunay or Poisson meshing is used to obtain a mesh from the point cloud.\n",
      "paper_title": "Pixelwise View Selection for Unstructured Multi-View Stereo",
      "paper_authors": [
        "Johannes Lutz Sch\u0151nberger",
        "Enliang Zheng",
        "Marc Pollefeys",
        "Jan-Michael Frahm"
      ],
      "paper_link": "https://demuc.de/papers/schoenberger2016mvs.pdf",
      "link": "https://colmap.github.io/",
      "licenses": [
        {
          "name": "BSD",
          "url": "https://colmap.github.io/license.html"
        }
      ],
      "nb_version": "1.0.3.dev2+g00cf083.d20240819",
      "num_iterations": 1,
      "total_train_time": 9576.6332,
      "resources_utilization": {
        "memory": 960,
        "gpu_name": "",
        "gpu_memory": 0
      },
      "datetime": "2024-09-01T21:22:07",
      "config_overrides": {},
      "applied_presets": [],
      "evaluation_protocol": "default",
      "checkpoint_sha256": "3d86dacf9c52f3e89bfa726016331099219f1272cb88f2d88b5f02978d412c5d"
    },
    "dataset_info": {
      "id": "tanksandtemples",
      "color_space": "srgb",
      "evaluation_protocol": "default",
      "scene": "truck",
      "type": "object-centric",
      "downscale_factor": 2,
      "expected_scene_scale": 4.9711024284362795,
      "name": "Tanks and Temples",
      "description": "Tanks and Temples is a benchmark for image-based 3D reconstruction. The benchmark sequences were acquired outside the lab, in realistic conditions. Ground-truth data was captured using an industrial laser scanner. The benchmark includes both outdoor scenes and indoor environments. The dataset is split into three subsets: training, intermediate, and advanced.",
      "paper_title": "Tanks and Temples: Benchmarking Large-Scale Scene Reconstruction",
      "paper_authors": [
        "Arno Knapitsch",
        "Jaesik Park",
        "Qian-Yi Zhou",
        "Vladlen Koltun"
      ],
      "paper_link": "https://storage.googleapis.com/t2-downloads/paper/tanks-and-temples.pdf",
      "link": "https://www.tanksandtemples.org/",
      "metrics": [
        {
          "id": "psnr",
          "name": "PSNR",
          "description": "Peak Signal to Noise Ratio. The higher the better.",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio"
        },
        {
          "id": "ssim",
          "name": "SSIM",
          "description": "Structural Similarity Index. The higher the better. The implementation matches JAX's SSIM and torchmetrics's SSIM (with default parameters).",
          "ascending": true,
          "link": "https://en.wikipedia.org/wiki/Structural_similarity"
        },
        {
          "id": "lpips",
          "name": "LPIPS",
          "description": "Learned Perceptual Image Patch Similarity. The lower the better. The implementation uses AlexNet backbone and matches lpips pip package with checkpoint version 0.1",
          "ascending": false,
          "link": "https://richzhang.github.io/PerceptualSimilarity/"
        }
      ],
      "default_metric": "psnr",
      "scenes": [
        {
          "id": "auditorium",
          "name": "auditorium"
        },
        {
          "id": "ballroom",
          "name": "ballroom"
        },
        {
          "id": "courtroom",
          "name": "courtroom"
        },
        {
          "id": "museum",
          "name": "museum"
        },
        {
          "id": "palace",
          "name": "palace"
        },
        {
          "id": "temple",
          "name": "temple"
        },
        {
          "id": "family",
          "name": "family"
        },
        {
          "id": "francis",
          "name": "francis"
        },
        {
          "id": "horse",
          "name": "horse"
        },
        {
          "id": "lighthouse",
          "name": "lighthouse"
        },
        {
          "id": "m60",
          "name": "m60"
        },
        {
          "id": "panther",
          "name": "panther"
        },
        {
          "id": "playground",
          "name": "playground"
        },
        {
          "id": "train",
          "name": "train"
        },
        {
          "id": "barn",
          "name": "barn"
        },
        {
          "id": "caterpillar",
          "name": "caterpillar"
        },
        {
          "id": "church",
          "name": "church"
        },
        {
          "id": "courthouse",
          "name": "courthouse"
        },
        {
          "id": "ignatius",
          "name": "ignatius"
        },
        {
          "id": "meetingroom",
          "name": "meetingroom"
        },
        {
          "id": "truck",
          "name": "truck"
        }
      ]
    }
  },
  "method_id": "colmap",
  "renderer": {
    "mesh_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/colmap/tanksandtemples/truck_demo/mesh.ply",
    "type": "mesh",
    "scene_url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-supplementary/resolve/main/colmap/tanksandtemples/truck_demo/params.json"
  },
  "dataset": {
    "url": "https://huggingface.co/datasets/nerfbaselines/nerfbaselines-data/resolve/main/tanksandtemples/truck-nbv.json"
  },
  "viewer_transform": [
    0.1454077104537557,
    0.026119456203799598,
    -0.12320364544828087,
    -0.02015829708594205,
    0.12564856958173082,
    -0.01724979689639089,
    0.14463626037756344,
    -0.09879495924347917,
    0.008590815998929944,
    -0.1898024826670958,
    -0.030099492263002056,
    0.1503578020779073
  ],
  "viewer_initial_pose": [
    0.1960246294527081,
    0.08639115208768383,
    -0.976786013648807,
    0.796161899663975,
    0.9802130370079851,
    -0.04520662240722972,
    0.19271408550953328,
    -0.032288999098732445,
    -0.02750839369458845,
    -0.9952351092124003,
    -0.093543347011357,
    0.11925081357745762
  ]
}